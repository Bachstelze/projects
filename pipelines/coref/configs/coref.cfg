[paths]
train = null
dev = null
init_tok2vec = null
vectors = null

[system]
gpu_allocator = "pytorch"
seed = 0

[nlp]
lang = "en"
pipeline = ["sentencizer", "transformer", "coref", "span_predictor"]
batch_size = 2
disabled = []
before_creation = null
after_creation = null
after_pipeline_creation = null
tokenizer = {"@tokenizers":"spacy.Tokenizer.v1"}

[components]

[components.sentencizer]
factory = "sentencizer"
punct_chars = null

[components.span_predictor]
source = "training/span_predictor/model-best"

[components.coref]
source = "training/cluster/model-best"

[components.transformer]
source = "training/cluster/model-best"
